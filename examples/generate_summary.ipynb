{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d62183-5b5e-4e7f-87c1-b2cae889c3ec",
   "metadata": {},
   "source": [
    "#### Sample module to generate summary from text corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1408b9f0-2956-45ae-afef-28a8ed15e621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.taggers import NLTKTagger\n",
    "from textblob.tokenizers import SentenceTokenizer\n",
    "from textblob.parsers import PatternParser\n",
    "from textblob.np_extractors import ConllExtractor\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5033f5a-c0ab-48be-ab88-a4ea1b6891bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = Blobber(pos_tagger=NLTKTagger(), \n",
    "            tokenizer=SentenceTokenizer(),\n",
    "            parser=PatternParser(),\n",
    "            np_extractor=ConllExtractor(),\n",
    "            analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77942020-3c3c-47b2-9b5c-9395d4fff48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8501488-7556-4884-afe7-bfb94e165e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summary:\n",
    "    \"\"\"Generates summary.\"\"\"\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "        self.words = text.split()\n",
    "\n",
    "    def generate_ngrams(self, n=4):\n",
    "        return self.text.ngrams(n)\n",
    "\n",
    "    def generate_parse_data(self):\n",
    "        data = self.text.parse().split(' ')\n",
    "        return [p.split('/',1) for p in data]\n",
    "\n",
    "    def generate_sentiment_data(self):\n",
    "        for s in self.text.sentences:\n",
    "            return [s, s.sentiment]\n",
    "\n",
    "    def generate_wordcount(self):\n",
    "        return self.text.word_counts\n",
    "\n",
    "    def generate_tokens(self):\n",
    "        return self.text.tokens\n",
    "\n",
    "    def generate_synsets(self):\n",
    "        unique = list(OrderedDict.fromkeys(self.words)) # remove duplicates\n",
    "        return [(w, w.synsets) for w in unique]\n",
    "\n",
    "    def generate_spell_suggestion(self):\n",
    "        words_ = list(OrderedDict.fromkeys(self.words))\n",
    "        suggestion = [(w, w.spellcheck()) for w in words_] \n",
    "        return suggestion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735801f9-5cc7-4e15-842e-716ee0e65ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'That woild be wondergul to have you on this labrary'\n",
    "q = tb(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a567f3f8-57f4-4e6c-9303-1d025371c55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Summary(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45287318-19c5-424e-8c68-0abc8d4dd4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'that': 1,\n",
       "             'woild': 1,\n",
       "             'be': 1,\n",
       "             'wondergul': 1,\n",
       "             'to': 1,\n",
       "             'have': 1,\n",
       "             'you': 1,\n",
       "             'on': 1,\n",
       "             'this': 1,\n",
       "             'labrary': 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.generate_wordcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1138948d-1ed4-4559-8a87-8629d1d8b406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['That', 'woild', 'be']),\n",
       " WordList(['woild', 'be', 'wondergul']),\n",
       " WordList(['be', 'wondergul', 'to']),\n",
       " WordList(['wondergul', 'to', 'have']),\n",
       " WordList(['to', 'have', 'you']),\n",
       " WordList(['have', 'you', 'on']),\n",
       " WordList(['you', 'on', 'this']),\n",
       " WordList(['on', 'this', 'labrary'])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.generate_ngrams(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a68cd68b-1d69-45df-8e29-6b6b7d1adf52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['That', 'DT/B-NP/O'],\n",
       " ['woild', 'NN/I-NP/O'],\n",
       " ['be', 'VB/B-VP/O'],\n",
       " ['wondergul', 'NN/B-NP/O'],\n",
       " ['to', 'TO/B-PP/O'],\n",
       " ['have', 'VBP/B-VP/O'],\n",
       " ['you', 'PRP/B-NP/O'],\n",
       " ['on', 'IN/B-PP/B-PNP'],\n",
       " ['this', 'DT/B-NP/I-PNP'],\n",
       " ['labrary', 'NN/I-NP/I-PNP']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.generate_parse_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8212508a-7e06-41e4-988b-a55a87d2c3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"That woild be wondergul to have you on this labrary\"),\n",
       " Sentiment(classification='neg', p_pos=0.46325421468243416, p_neg=0.5367457853175658)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.generate_sentiment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da424f0-f13a-47a0-b1bf-481cec76eef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('That',\n",
       "  [('That', 0.8001534821257275),\n",
       "   ('What', 0.1925561169022191),\n",
       "   ('Hat', 0.006714843000575558),\n",
       "   ('Chat', 0.0005755579714779049)]),\n",
       " ('woild',\n",
       "  [('would', 0.831063829787234),\n",
       "   ('world', 0.15404255319148935),\n",
       "   ('wild', 0.014893617021276596)]),\n",
       " ('be', [('be', 1.0)]),\n",
       " ('wondergul', [('wonderful', 1.0)]),\n",
       " ('to', [('to', 1.0)]),\n",
       " ('have', [('have', 1.0)]),\n",
       " ('you', [('you', 1.0)]),\n",
       " ('on', [('on', 1.0)]),\n",
       " ('this', [('this', 1.0)]),\n",
       " ('labrary', [('library', 1.0)])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.generate_spell_suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "118822a4-69d7-4566-8337-7af3daa94607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('That', []),\n",
       " ('woild', []),\n",
       " ('be',\n",
       "  [Synset('beryllium.n.01'),\n",
       "   Synset('be.v.01'),\n",
       "   Synset('be.v.02'),\n",
       "   Synset('be.v.03'),\n",
       "   Synset('exist.v.01'),\n",
       "   Synset('be.v.05'),\n",
       "   Synset('equal.v.01'),\n",
       "   Synset('constitute.v.01'),\n",
       "   Synset('be.v.08'),\n",
       "   Synset('embody.v.02'),\n",
       "   Synset('be.v.10'),\n",
       "   Synset('be.v.11'),\n",
       "   Synset('be.v.12'),\n",
       "   Synset('cost.v.01')]),\n",
       " ('wondergul', []),\n",
       " ('to', []),\n",
       " ('have',\n",
       "  [Synset('rich_person.n.01'),\n",
       "   Synset('have.v.01'),\n",
       "   Synset('have.v.02'),\n",
       "   Synset('experience.v.03'),\n",
       "   Synset('own.v.01'),\n",
       "   Synset('get.v.03'),\n",
       "   Synset('consume.v.02'),\n",
       "   Synset('have.v.07'),\n",
       "   Synset('hold.v.03'),\n",
       "   Synset('have.v.09'),\n",
       "   Synset('have.v.10'),\n",
       "   Synset('have.v.11'),\n",
       "   Synset('have.v.12'),\n",
       "   Synset('induce.v.02'),\n",
       "   Synset('accept.v.02'),\n",
       "   Synset('receive.v.01'),\n",
       "   Synset('suffer.v.02'),\n",
       "   Synset('have.v.17'),\n",
       "   Synset('give_birth.v.01'),\n",
       "   Synset('take.v.35')]),\n",
       " ('you', []),\n",
       " ('on',\n",
       "  [Synset('on.a.01'),\n",
       "   Synset('on.a.02'),\n",
       "   Synset('along.r.01'),\n",
       "   Synset('on.r.02'),\n",
       "   Synset('on.r.03')]),\n",
       " ('this', []),\n",
       " ('labrary', [])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.generate_synsets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "513f0019-99ba-4fe0-9dcc-d6b4a1284232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['That woild be wondergul to have you on this labrary'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.generate_tokens() # senetence tokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
